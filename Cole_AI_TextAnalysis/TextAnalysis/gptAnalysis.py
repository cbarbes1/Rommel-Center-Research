''' 
Author: Cole Barbes
Last edited: 03/27/2024
Analyze abstracts to determine a set of categories
'''
import openai
import random
import os
import json
#mport arxiv
#from nltk.corpus import wordnet

API_KEY = os.getenv('OPENAI_API_KEY')

# Here we define the various prompts we will need within this framework of analysis functions

__format = """{ "Top-Level-Category" : { "mid-level-category": "low-level-category", "..."} }"""

__format2 = """{
    "Computer Science": {
        "Tree structures": "Red-Black Tree",
        "Parallel Computing": "OpenMPI"
    },
    "Artificial Intelligence": {
        "Natural Language Processing": "Large Language Models",
    },
    "Machine Learning": {
        "Supervised Learning":"Random Forest",
        "Unsupervised Learning":"Clustering",
    }
}"""

__task = """You are a expert at generating Taxonomies from text. Users will prompt you with blocks of text and you are to do as follows. \
    I should be able to search each category and find college majors and research areas not just words \
    Analyze the text they give you and Generate a category taxonomy from: the text, your analysis and the summary you create. \
    Please find a hierarchy of topics 
    Output the taxonomy in JSON\
    <Parent Category> : <Child Category>, <Child Category> \
    This should be a concise category like Computer Science
    Only give about 5 or 6 categories, they should be categories from this site https://arxiv.org/category_taxonomy\
    The caregories should not be sentences
    Here is an example taxonomy:
    machine learning 1st level
    learning paradigms 2nd level
    cross validation 2nd level -> supervised learning 3rd level, unsupervised learning 3rd level
    To be a successful taxonomy, It should look as follows {__format} in JSON \
    """
__initial_prompt__ = f"""
You are an expert constructing a category taxonomy from an abstract to output JSON. \
The output should be as follows: {__format}
Given a list of predefined categories and topics \
Please find a hierarchy of topics 
Output the taxonomy in JSON\
<Parent Category> : <Child Category>, <Child Category> \
This should be a concise category like Computer Science
Only give about 5 or 6 categories, they should be categories from this site https://arxiv.org/category_taxonomy\
each entry should be a substantial category or theme of the abstract.
heres how it should look
{__format2}
"""


# abstract from outside institution for testing
__test_abstract = f"""\
    Taxonomies represent hierarchical relations between 
entities, frequently applied in various software modeling and
natural language processing (NLP) activities. They are typically
subject to a set of structural constraints restricting their content.
However, manual taxonomy construction can be time-consuming,
incomplete, and costly to maintain. Recent studies of large
language models (LLMs) have demonstrated that appropriate
user inputs (called prompting) can effectively guide LLMs, such
as GPT-3, in diverse NLP tasks without explicit (re-)training.
However, existing approaches for automated taxonomy construc-
tion typically involve fine-tuning a language model by adjusting
model parameters. In this paper, we present a general framework
for taxonomy construction that takes into account structural
constraints. We subsequently conduct a systematic comparison
between the prompting and fine-tuning approaches performed on
a hypernym taxonomy and a novel computer science taxonomy
dataset. Our result reveals the following: (1) Even without explicit
training on the dataset, the prompting approach outperforms
fine-tuning-based approaches. Moreover, the performance gap
between prompting and fine-tuning widens when the training
dataset is small. However, (2) taxonomies generated by the
fine-tuning approach can be easily post-processed to satisfy all
the constraints, whereas handling violations of the taxonomies
produced by the prompting approach can be challenging. These
evaluation findings provide guidance on selecting the appropri-
ate method for taxonomy construction and highlight potential
enhancements for both approaches.
"""

"""
This function prompts the openai api and returns the output
Parameters: The message in open ai format, the model, the temperature, and the maximum token size
Return: The output content in human readable format
"""
def get_response(messages, model='gpt-3.5-turbo', temperature=0.5, max_tokens=500):
    # below we set the model and the parameters like the message etc...
    response = openai.chat.completions.create(
        model=model,
        messages = messages, 
        # temperature is how deterministic the model will be
        temperature=temperature,
        max_tokens=max_tokens,
    )
    return response.choices[0].message.content


"""
This function creates a taxonomy of a random list of abstracts and outputs to json
parameters: The abstract list, the prompt and the number of abstracts
print to json file
"""
def get_taxonomy_abstracts(Abstracts, prompt, num_iter=10):
    file_name = "Taxonomy.json"
    rand_index = random.randint(0, len(Abstracts))
    Abstract_range = Abstracts[rand_index:rand_index+num_iter]
    with open(file_name, 'w') as file:
        json_output = {}
        for abstract in Abstract_range:
            # this sets up the message in open ai format
            messages = [
                {'role':'system', 'content':prompt},
                {'role':'user', 'content': abstract},
            ]
            # call the response creation function
            output_taxonomy = get_response(messages=messages)
            json_output[abstract] = json.loads(output_taxonomy) # places a dictionary at every entry 
        json.dump(json_output, file, indent=4) ## dump the dictionary into the file
    print("Taxonomy of abstracts Complete")

if __name__ == "__main__":
    with open('abstracts_to_categories.json', 'r') as file:
        data = json.load(file)
    abstract_list = [key for key, __ in data.items()]
    get_taxonomy_abstracts(abstract_list, __initial_prompt__)